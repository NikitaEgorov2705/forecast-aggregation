{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "required_packages = [\n",
    "    \"pandas\", \n",
    "    \"scikit-learn\",  # for the calsulation of the Brier Score\n",
    "    \"scipy\",         # for the geometrics means\n",
    "    \"numpy\"\n",
    "]\n",
    "\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        __import__(package)\n",
    "    except ImportError:\n",
    "        install_package(package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "qa_df = pd.read_csv('rct-a-questions-answers.csv')\n",
    "daily_forecasts_df = pd.read_csv('rct-a-daily-forecasts.csv')\n",
    "prediction_sets_df = pd.read_csv('rct-a-prediction-sets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Competition questions, Questions and Answers: 343\n",
      "Number of Competition questions, Daily Forecasts: 187\n",
      "Number of Competition questions, Prediction Sets: 193\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Competition questions, Questions and Answers:\", qa_df['discover question id'].nunique())\n",
    "print(\"Number of Competition questions, Daily Forecasts:\", daily_forecasts_df['discover question id'].nunique())\n",
    "print(\"Number of Competition questions, Prediction Sets:\", prediction_sets_df['discover question id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['How many battle deaths will ACLED record in Sudan in August 2017?'\n",
      " \"Will ACLED record any riot/protest events in the Cote d'Ivoire (Ivory Coast) during August 2017?\"\n",
      " 'Will FEWS NET publish a Food Security Alert with \"famine\" and \"Yemen\" in its headline between 9 August 2017 and 25 October 2017?'\n",
      " 'Will the Political Instability Task Force (PITF) Worldwide Atrocities Dataset record an event perpetrated by a non-state actor in Israel that starts between 9 August 2017 and 31 August 2017, inclusive?'\n",
      " \"How many 'hacking or malware (HACK)' data breaches will Privacy Rights Clearinghouse record for September 2017?\"\n",
      " 'How much crude oil will Libya produce in September 2017?'\n",
      " 'What will the short-term interest rate be for Ireland (IRL) in August 2017?'\n",
      " 'What will the monthly percent change in the consumer price index (CPI) be for Estonia in August 2017?'\n",
      " 'How many UN member states will sign the Treaty on the Prohibition of Nuclear Weapons before 1 November 2017?'\n",
      " 'What will the long-term interest rate be for Colombia (COL) in August 2017?'\n",
      " 'What will be the approval rate for Japan’s cabinet in NHK’s monthly survey in September 2017?'\n",
      " 'Will ACLED record any riot/protest events in Senegal during September 2017?'\n",
      " 'Will the Political Instability Task Force (PITF) Worldwide Atrocities Dataset record an event perpetrated by a non-state actor in Honduras (HND) that starts between 1 September 2017 and 30 September 2017?'\n",
      " 'What will the long-term interest rate be for South Africa (ZAF) in August 2017?'\n",
      " 'What will the daily price of the Brazilian real-to-US dollar exchange rate be on 31 October 2017?']\n"
     ]
    }
   ],
   "source": [
    "print(qa_df['question name'].unique()[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of variables, Questions dataset: 38\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['discover question id', 'question name', 'creator id',\n",
       "       'question starts at', 'question ends at', 'question description',\n",
       "       'question status', 'question published at', 'question resolved at',\n",
       "       'question correctness known at', 'use ordinal scoring',\n",
       "       'question created at', 'question tags', 'question challenges',\n",
       "       'discover answer id', 'answer name', 'answer initial probability',\n",
       "       'answer sort order', 'answer resolved at', 'answer resolved by user id',\n",
       "       'answer resolved probability', 'answer correctness known at',\n",
       "       'answer created at', 'clarification 1', 'clarification 2',\n",
       "       'clarification 3', 'IFP Generation Method', 'Country - Primary',\n",
       "       'Country - Secondary', 'Topic', 'Region',\n",
       "       'Non-state violence (Terrorism)', 'Domain', 'Created By', 'Deaths',\n",
       "       'RCT', 'Controversial',\n",
       "       'Departure from Status Quo Resolution (Binary Only)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of variables, Questions dataset:\", qa_df.shape[1])\n",
    "qa_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median number of answers submitted per question: 3.0\n",
      "Min. number of answers per question: 1\n",
      "Max. number of answers per question: 5\n"
     ]
    }
   ],
   "source": [
    "answer_counts = qa_df.groupby('discover question id')['discover answer id'].count()\n",
    "print(\"Median number of answers submitted per question:\", answer_counts.median())\n",
    "print(\"Min. number of answers per question:\", answer_counts.min())\n",
    "print(\"Max. number of answers per question:\", answer_counts.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"rct-a-questions-answers\" dataset contains 343 forecasting questions posed to participants, along with their corresponding answers. It includes variables that describe the topics of the questions, their contexts, and the criteria for resolution. Additionally, the dataset includes IDs for both topics and respondents, timestamps for when the questions were published and resolved, geographical region attributions, probabilities of predicted outcomes with some other charasterisrics. The number of answers submitted to each question varies, with a median of 3 answers per question, and a range of 1 to 5 answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily forecasts dataset structure: (9251564, 11)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['date', 'discover question id', 'discover answer id', 'site id',\n",
       "       'external predictor id', 'question id', 'answer id',\n",
       "       'external prediction id', 'external prediction set id', 'created at',\n",
       "       'forecast'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Daily forecasts dataset structure:\", daily_forecasts_df.shape)\n",
    "daily_forecasts_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>discover question id</th>\n",
       "      <th>discover answer id</th>\n",
       "      <th>site id</th>\n",
       "      <th>external predictor id</th>\n",
       "      <th>question id</th>\n",
       "      <th>answer id</th>\n",
       "      <th>external prediction id</th>\n",
       "      <th>external prediction set id</th>\n",
       "      <th>created at</th>\n",
       "      <th>forecast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-03-07T14:00:59-05:00</td>\n",
       "      <td>177</td>\n",
       "      <td>561</td>\n",
       "      <td>5</td>\n",
       "      <td>78</td>\n",
       "      <td>820</td>\n",
       "      <td>2471</td>\n",
       "      <td>6892</td>\n",
       "      <td>2359</td>\n",
       "      <td>2018-03-07T18:31:21Z</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-03-07T14:00:59-05:00</td>\n",
       "      <td>177</td>\n",
       "      <td>559</td>\n",
       "      <td>5</td>\n",
       "      <td>77</td>\n",
       "      <td>820</td>\n",
       "      <td>2473</td>\n",
       "      <td>6885</td>\n",
       "      <td>2358</td>\n",
       "      <td>2018-03-07T18:31:21Z</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-03-07T14:00:59-05:00</td>\n",
       "      <td>177</td>\n",
       "      <td>558</td>\n",
       "      <td>5</td>\n",
       "      <td>65</td>\n",
       "      <td>820</td>\n",
       "      <td>2474</td>\n",
       "      <td>6824</td>\n",
       "      <td>2346</td>\n",
       "      <td>2018-03-07T18:31:20Z</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-03-07T14:00:59-05:00</td>\n",
       "      <td>177</td>\n",
       "      <td>558</td>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>820</td>\n",
       "      <td>2474</td>\n",
       "      <td>6879</td>\n",
       "      <td>2357</td>\n",
       "      <td>2018-03-07T18:31:21Z</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-03-07T14:00:59-05:00</td>\n",
       "      <td>177</td>\n",
       "      <td>559</td>\n",
       "      <td>5</td>\n",
       "      <td>57</td>\n",
       "      <td>820</td>\n",
       "      <td>2473</td>\n",
       "      <td>6785</td>\n",
       "      <td>2338</td>\n",
       "      <td>2018-03-07T18:31:18Z</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date  discover question id  discover answer id  \\\n",
       "0  2018-03-07T14:00:59-05:00                   177                 561   \n",
       "1  2018-03-07T14:00:59-05:00                   177                 559   \n",
       "2  2018-03-07T14:00:59-05:00                   177                 558   \n",
       "3  2018-03-07T14:00:59-05:00                   177                 558   \n",
       "4  2018-03-07T14:00:59-05:00                   177                 559   \n",
       "\n",
       "   site id  external predictor id  question id  answer id  \\\n",
       "0        5                     78          820       2471   \n",
       "1        5                     77          820       2473   \n",
       "2        5                     65          820       2474   \n",
       "3        5                     76          820       2474   \n",
       "4        5                     57          820       2473   \n",
       "\n",
       "   external prediction id  external prediction set id            created at  \\\n",
       "0                    6892                        2359  2018-03-07T18:31:21Z   \n",
       "1                    6885                        2358  2018-03-07T18:31:21Z   \n",
       "2                    6824                        2346  2018-03-07T18:31:20Z   \n",
       "3                    6879                        2357  2018-03-07T18:31:21Z   \n",
       "4                    6785                        2338  2018-03-07T18:31:18Z   \n",
       "\n",
       "   forecast  \n",
       "0       0.2  \n",
       "1       0.2  \n",
       "2       0.2  \n",
       "3       0.2  \n",
       "4       0.2  "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_forecasts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of participating entities: 7\n",
      "Total number of models or methods used by participants: 320\n",
      "Total number of forecast entries: 9251564\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of participating entities:\", daily_forecasts_df['site id'].nunique())\n",
    "print(\"Total number of models or methods used by participants:\", daily_forecasts_df['external predictor id'].nunique())\n",
    "\n",
    "print(f\"Total number of forecast entries: {daily_forecasts_df.shape[0]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"rct-a-daily-forecasts\" dataset contains the most recent predictions submitted by various forecasting methods or models from 7 participating entities.\n",
    "Each forecast is associated with a specific question (\"question id\") and an answer option (\"answer id\") within that question.'forecast' values capture the probability of these forecasted outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction set id</th>\n",
       "      <th>membership guid</th>\n",
       "      <th>discover question id</th>\n",
       "      <th>question id</th>\n",
       "      <th>question name</th>\n",
       "      <th>prediction set created at</th>\n",
       "      <th>prediction set updated at</th>\n",
       "      <th>rationale</th>\n",
       "      <th>comment id</th>\n",
       "      <th>prediction id</th>\n",
       "      <th>...</th>\n",
       "      <th>answer resolved probability</th>\n",
       "      <th>answer sort order</th>\n",
       "      <th>question ends_at</th>\n",
       "      <th>question published_at</th>\n",
       "      <th>question starts_at</th>\n",
       "      <th>question resolved_at</th>\n",
       "      <th>question correctness_known_at</th>\n",
       "      <th>question use_ordinal_scoring</th>\n",
       "      <th>site id</th>\n",
       "      <th>site name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>340</td>\n",
       "      <td>52d0b6592281f0d274d93661cf2ef1dd26f55d28</td>\n",
       "      <td>182</td>\n",
       "      <td>807</td>\n",
       "      <td>Practice Question: Will there be a new prime m...</td>\n",
       "      <td>2018-02-28T20:16:37Z</td>\n",
       "      <td>2018-02-28T20:16:37Z</td>\n",
       "      <td>Given that the negotiation of Brexit is still ...</td>\n",
       "      <td>391</td>\n",
       "      <td>704</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-06T19:00:41Z</td>\n",
       "      <td>2018-02-26T17:05:25Z</td>\n",
       "      <td>2018-02-26T16:49:41Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "      <td>HFC Carbon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>341</td>\n",
       "      <td>52d0b6592281f0d274d93661cf2ef1dd26f55d28</td>\n",
       "      <td>183</td>\n",
       "      <td>816</td>\n",
       "      <td>Practice Question: What will be the daily clos...</td>\n",
       "      <td>2018-02-28T20:18:42Z</td>\n",
       "      <td>2018-02-28T20:18:42Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>392</td>\n",
       "      <td>705</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-11T18:00:43Z</td>\n",
       "      <td>2018-02-26T17:05:27Z</td>\n",
       "      <td>2018-02-26T17:00:01Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "      <td>HFC Carbon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>341</td>\n",
       "      <td>52d0b6592281f0d274d93661cf2ef1dd26f55d28</td>\n",
       "      <td>183</td>\n",
       "      <td>816</td>\n",
       "      <td>Practice Question: What will be the daily clos...</td>\n",
       "      <td>2018-02-28T20:18:42Z</td>\n",
       "      <td>2018-02-28T20:18:42Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>392</td>\n",
       "      <td>706</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-03-11T18:00:43Z</td>\n",
       "      <td>2018-02-26T17:05:27Z</td>\n",
       "      <td>2018-02-26T17:00:01Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "      <td>HFC Carbon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>341</td>\n",
       "      <td>52d0b6592281f0d274d93661cf2ef1dd26f55d28</td>\n",
       "      <td>183</td>\n",
       "      <td>816</td>\n",
       "      <td>Practice Question: What will be the daily clos...</td>\n",
       "      <td>2018-02-28T20:18:42Z</td>\n",
       "      <td>2018-02-28T20:18:42Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>392</td>\n",
       "      <td>707</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-03-11T18:00:43Z</td>\n",
       "      <td>2018-02-26T17:05:27Z</td>\n",
       "      <td>2018-02-26T17:00:01Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "      <td>HFC Carbon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>341</td>\n",
       "      <td>52d0b6592281f0d274d93661cf2ef1dd26f55d28</td>\n",
       "      <td>183</td>\n",
       "      <td>816</td>\n",
       "      <td>Practice Question: What will be the daily clos...</td>\n",
       "      <td>2018-02-28T20:18:42Z</td>\n",
       "      <td>2018-02-28T20:18:42Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>392</td>\n",
       "      <td>708</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-03-11T18:00:43Z</td>\n",
       "      <td>2018-02-26T17:05:27Z</td>\n",
       "      <td>2018-02-26T17:00:01Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "      <td>HFC Carbon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   prediction set id                           membership guid  \\\n",
       "0                340  52d0b6592281f0d274d93661cf2ef1dd26f55d28   \n",
       "1                341  52d0b6592281f0d274d93661cf2ef1dd26f55d28   \n",
       "2                341  52d0b6592281f0d274d93661cf2ef1dd26f55d28   \n",
       "3                341  52d0b6592281f0d274d93661cf2ef1dd26f55d28   \n",
       "4                341  52d0b6592281f0d274d93661cf2ef1dd26f55d28   \n",
       "\n",
       "   discover question id  question id  \\\n",
       "0                   182          807   \n",
       "1                   183          816   \n",
       "2                   183          816   \n",
       "3                   183          816   \n",
       "4                   183          816   \n",
       "\n",
       "                                       question name  \\\n",
       "0  Practice Question: Will there be a new prime m...   \n",
       "1  Practice Question: What will be the daily clos...   \n",
       "2  Practice Question: What will be the daily clos...   \n",
       "3  Practice Question: What will be the daily clos...   \n",
       "4  Practice Question: What will be the daily clos...   \n",
       "\n",
       "  prediction set created at prediction set updated at  \\\n",
       "0      2018-02-28T20:16:37Z      2018-02-28T20:16:37Z   \n",
       "1      2018-02-28T20:18:42Z      2018-02-28T20:18:42Z   \n",
       "2      2018-02-28T20:18:42Z      2018-02-28T20:18:42Z   \n",
       "3      2018-02-28T20:18:42Z      2018-02-28T20:18:42Z   \n",
       "4      2018-02-28T20:18:42Z      2018-02-28T20:18:42Z   \n",
       "\n",
       "                                           rationale  comment id  \\\n",
       "0  Given that the negotiation of Brexit is still ...         391   \n",
       "1                                                NaN         392   \n",
       "2                                                NaN         392   \n",
       "3                                                NaN         392   \n",
       "4                                                NaN         392   \n",
       "\n",
       "   prediction id  ...  answer resolved probability answer sort order  \\\n",
       "0            704  ...                          NaN                 0   \n",
       "1            705  ...                          NaN                 0   \n",
       "2            706  ...                          NaN                 1   \n",
       "3            707  ...                          NaN                 2   \n",
       "4            708  ...                          NaN                 3   \n",
       "\n",
       "       question ends_at question published_at    question starts_at  \\\n",
       "0  2018-03-06T19:00:41Z  2018-02-26T17:05:25Z  2018-02-26T16:49:41Z   \n",
       "1  2018-03-11T18:00:43Z  2018-02-26T17:05:27Z  2018-02-26T17:00:01Z   \n",
       "2  2018-03-11T18:00:43Z  2018-02-26T17:05:27Z  2018-02-26T17:00:01Z   \n",
       "3  2018-03-11T18:00:43Z  2018-02-26T17:05:27Z  2018-02-26T17:00:01Z   \n",
       "4  2018-03-11T18:00:43Z  2018-02-26T17:05:27Z  2018-02-26T17:00:01Z   \n",
       "\n",
       "   question resolved_at  question correctness_known_at  \\\n",
       "0                   NaN                            NaN   \n",
       "1                   NaN                            NaN   \n",
       "2                   NaN                            NaN   \n",
       "3                   NaN                            NaN   \n",
       "4                   NaN                            NaN   \n",
       "\n",
       "   question use_ordinal_scoring  site id   site name  \n",
       "0                         False       11  HFC Carbon  \n",
       "1                          True       11  HFC Carbon  \n",
       "2                          True       11  HFC Carbon  \n",
       "3                          True       11  HFC Carbon  \n",
       "4                          True       11  HFC Carbon  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_sets_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of individual forecasters: 5062\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of individual forecasters:\", prediction_sets_df['membership guid'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"rct-a-prediction-sets\" dataset contains detailed records of individual-level forecasts submitted by competing entities. In total it contains the forecasts from 5062 individual forecasters, each identified by a unique membership GUID. The 'rationale' variable contains the explanations given by the forecasters in support to their prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_sets_df['filled at'] = pd.to_datetime(prediction_sets_df['filled at'])\n",
    "\n",
    "prediction_sets_df = prediction_sets_df.sort_values(by=['membership guid', 'discover question id', 'answer id', 'prediction set id', 'filled at'],\n",
    "                                                    ascending=[True, True, True, True, False])\n",
    "\n",
    "# create a column with the date of the forecast, without the exact time\n",
    "prediction_sets_df['date'] = prediction_sets_df['filled at'].dt.date\n",
    "\n",
    "# keeping only the most recent forecast for each forecaster, question, set and answer per every day\n",
    "individual_daily_forecasts_df = prediction_sets_df.drop_duplicates(\n",
    "    subset=['membership guid', 'discover question id', 'answer id', 'prediction set id', 'date'],\n",
    "    keep='first'\n",
    ")\n",
    "\n",
    "individual_daily_forecasts_columns = [\n",
    "    'date',\n",
    "    'discover question id',\n",
    "    'membership guid',\n",
    "    'answer id',\n",
    "    'forecasted probability'\n",
    "]\n",
    "\n",
    "individual_daily_forecasts_df = individual_daily_forecasts_df[individual_daily_forecasts_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique question-day pairs 13139\n"
     ]
    }
   ],
   "source": [
    "# check of the number of day-question pairs\n",
    "unique_question_day_pairs = prediction_sets_df[['discover question id', 'date']].drop_duplicates().sort_values(by=['discover question id', 'date'], ascending=True)\n",
    "print(\"Unique question-day pairs\", unique_question_day_pairs.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in key columns: date                      0\n",
      "discover question id      0\n",
      "membership guid           0\n",
      "answer id                 0\n",
      "forecasted probability    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values = individual_daily_forecasts_df.isnull().sum()\n",
    "print(\"Missing values in key columns:\", missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates: 32607\n"
     ]
    }
   ],
   "source": [
    "num_duplicates = individual_daily_forecasts_df.duplicated().sum()\n",
    "print(f\"Number of duplicates: {num_duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date                       object\n",
      "discover question id        int64\n",
      "membership guid            object\n",
      "answer id                   int64\n",
      "forecasted probability    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(individual_daily_forecasts_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregations\n",
    "\n",
    "I aggregate the data by:\n",
    "\n",
    "- Competition questions (\"discover question id\"): it has a global identifier for each unique competition question across the entire forecasting tournament (unlike the \"question id\", which varies across competitors)\n",
    "- Answer (\"answer id\"): it identifies the unique answers given by the competitors within the range of answers for each question. This ensures that forecasts are aggregated for each potential answer option within the question.\n",
    "- Date (\"date\"): this variable is used for aggregation, since we are interested in the most recent forecast per day from every competitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Raw mean\n",
    "# Calculate the simple average of the forecasted probabilities for each question-day-answer\n",
    "grouped_idf_df = individual_daily_forecasts_df.groupby(['discover question id', 'answer id', 'date'])\n",
    "# individual_daily_forecasts_df = individual_daily_forecasts_df.groupby(['discover question id', 'date', 'answer id', 'answer name'])\n",
    "\n",
    "raw_mean_df = grouped_idf_df['forecasted probability'].mean().reset_index(name='raw_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics of Raw Mean:\n",
      "count    157519.000000\n",
      "mean          0.236800\n",
      "std           0.264033\n",
      "min           0.000000\n",
      "25%           0.025000\n",
      "50%           0.140000\n",
      "75%           0.358894\n",
      "max           1.000000\n",
      "Name: raw_mean, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Summary statistics of Raw Mean:\")\n",
    "print(raw_mean_df['raw_mean'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Median\n",
    "# Calculate the median of the forecasted probabilities for each question-day-answer\n",
    "median_df = grouped_idf_df['forecasted probability'].median().reset_index(name='median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics of Median:\n",
      "count    157519.000000\n",
      "mean          0.227932\n",
      "std           0.273743\n",
      "min           0.000000\n",
      "25%           0.010000\n",
      "50%           0.110000\n",
      "75%           0.350000\n",
      "max           1.000000\n",
      "Name: median, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Summary statistics of Median:\")\n",
    "print(median_df['median'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Geometric Mean\n",
    "# Calculate the geometric mean of the forecasted probabilities for each question-day-answer\n",
    "\n",
    "from scipy.stats import gmean\n",
    "\n",
    "geometric_mean_df = grouped_idf_df['forecasted probability'].apply(gmean).reset_index(name='geometric_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics of Geometric Mean:\n",
      "count    157519.000000\n",
      "mean          0.188625\n",
      "std           0.266226\n",
      "min           0.000000\n",
      "25%           0.000000\n",
      "50%           0.050000\n",
      "75%           0.282672\n",
      "max           1.000000\n",
      "Name: geometric_mean, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Summary statistics of Geometric Mean:\")\n",
    "print(geometric_mean_df['geometric_mean'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trimmed Mean (trimming top and bottom 10% of forecasts)\n",
    "# Calculate the trimmed mean of the forecasted probabilities for each question-day-answer\n",
    "# Trimmed mean is calculated by removing the top and bottom 10% of the forecasts and then calculating the mean of the remaining forecasts.\n",
    "\n",
    "from scipy.stats import trim_mean\n",
    "trimmed_mean_df = grouped_idf_df['forecasted probability'].apply(lambda x: trim_mean(x, proportiontocut=0.1)).reset_index(name='trimmed_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics of Trimmed Mean (10 percent cut):\n",
      "count    157519.000000\n",
      "mean          0.235645\n",
      "std           0.264799\n",
      "min           0.000000\n",
      "25%           0.025000\n",
      "50%           0.137325\n",
      "75%           0.356667\n",
      "max           1.000000\n",
      "Name: trimmed_mean, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Summary statistics of Trimmed Mean (10 percent cut):\")\n",
    "print(trimmed_mean_df['trimmed_mean'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 Geometric Mean of Odds\n",
    "# Calculate the geometric mean of the odds of the forecasted probabilities for each question-day-answer\n",
    "\n",
    "# geom_mean_odds = individual_daily_forecasts_df.obj\n",
    "geom_mean_odds = individual_daily_forecasts_df\n",
    "\n",
    "geom_mean_odds['odds'] = geom_mean_odds['forecasted probability'] / (1 - geom_mean_odds['forecasted probability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics of Odds:\n",
      "count    7.501810e+05\n",
      "mean              inf\n",
      "std               NaN\n",
      "min      0.000000e+00\n",
      "25%      1.010101e-02\n",
      "50%      1.272686e-01\n",
      "75%      6.393443e-01\n",
      "max               inf\n",
      "Name: odds, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Homo Nicetas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
      "  sqr = _ensure_numeric((avg - values) ** 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Summary statistics of Odds:\")\n",
    "print(geom_mean_odds['odds'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Homo Nicetas\\AppData\\Local\\Temp\\ipykernel_17192\\503182684.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  geom_mean_odds['odds'].replace([np.inf], 7, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "## since there are infinite values, we need to replace them with a finite large number to mark them as 100% certain event\n",
    "## the 75% value is 6, so I replace infinite value with 7 as a cutoff of the certain event\n",
    "geom_mean_odds['odds'].replace([np.inf], 7, inplace=True)\n",
    "\n",
    "geom_mean_odds = geom_mean_odds.groupby(['discover question id', 'answer id', 'date'])\n",
    "geom_mean_odds = geom_mean_odds['odds'].apply(gmean).reset_index(name='geom_mean_of_odds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_df = raw_mean_df.merge(median_df, on=['discover question id', 'answer id', 'date'])\n",
    "aggregated_df = aggregated_df.merge(geometric_mean_df, on=['discover question id', 'answer id', 'date'])\n",
    "aggregated_df = aggregated_df.merge(trimmed_mean_df, on=['discover question id', 'answer id', 'date'])\n",
    "aggregated_df = aggregated_df.merge(geom_mean_odds, on=['discover question id', 'answer id', 'date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculation of the Brier score: How do the aggregation methods perform on the competition data?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions & Answers dataset, Resolved Probabilities:\n",
      "[ 0.  1. nan]\n",
      "0    0.0\n",
      "1    1.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "Name: answer resolved probability, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Questions & Answers dataset, Resolved Probabilities:\")\n",
    "print(qa_df['answer resolved probability'].unique())\n",
    "print(qa_df['answer resolved probability'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        13\n",
      "1        14\n",
      "2        15\n",
      "3        16\n",
      "4        17\n",
      "       ... \n",
      "950    1105\n",
      "951    1106\n",
      "952    1107\n",
      "953    1108\n",
      "954    1109\n",
      "Name: discover answer id, Length: 955, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(qa_df[\"discover answer id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to merge the dataset with calculated aggregations (aggregated_df) with the answers with resolved probabilities from Questions & Answers dataset (qa_df)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_id_df = daily_forecasts_df[['discover question id', 'answer id', 'discover answer id']]\n",
    "answer_id_df = answer_id_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_df['discover question id'] = aggregated_df['discover question id'].astype('category')\n",
    "aggregated_df['answer id'] = aggregated_df['answer id'].astype('category')\n",
    "for col in aggregated_df.select_dtypes(include=['float64']).columns:\n",
    "    aggregated_df[col] = aggregated_df[col].astype('float32')\n",
    "\n",
    "answer_id_df['discover question id'] = answer_id_df['discover question id'].astype('category')\n",
    "answer_id_df['discover answer id'] = answer_id_df['discover answer id'].astype('category')\n",
    "answer_id_df['answer id'] = answer_id_df['answer id'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_aggregated_df = aggregated_df.merge(answer_id_df,\n",
    "                                on=['discover question id', 'answer id'],\n",
    "                                how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing entries in Discover Answer ID after merging: 463 out of 157519 (0.29%)\n"
     ]
    }
   ],
   "source": [
    "missing_values_count = id_aggregated_df['discover answer id'].isnull().sum()\n",
    "total_entries_count = len(id_aggregated_df)\n",
    "\n",
    "print(f\"Missing entries in Discover Answer ID after merging: {missing_values_count} out of {total_entries_count} ({missing_values_count / total_entries_count:.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_aggregated_df = id_aggregated_df.dropna(subset=['discover answer id'])\n",
    "id_aggregated_df[['discover question id', 'discover answer id', 'answer id']] = id_aggregated_df[['discover question id', 'discover answer id', 'answer id']].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Homo Nicetas\\AppData\\Local\\Temp\\ipykernel_17192\\3127621872.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  resolved_probabilities_df['discover question id'] = resolved_probabilities_df['discover question id'].astype('category')\n",
      "C:\\Users\\Homo Nicetas\\AppData\\Local\\Temp\\ipykernel_17192\\3127621872.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  resolved_probabilities_df['discover answer id'] = resolved_probabilities_df['discover answer id'].astype('category')\n"
     ]
    }
   ],
   "source": [
    "resolved_probabilities_df = qa_df[['discover question id', 'discover answer id', 'answer name', 'answer resolved probability']]\n",
    "\n",
    "resolved_probabilities_df['discover question id'] = resolved_probabilities_df['discover question id'].astype('category')\n",
    "resolved_probabilities_df['discover answer id'] = resolved_probabilities_df['discover answer id'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discover question id</th>\n",
       "      <th>answer id</th>\n",
       "      <th>date</th>\n",
       "      <th>raw_mean</th>\n",
       "      <th>median</th>\n",
       "      <th>geometric_mean</th>\n",
       "      <th>trimmed_mean</th>\n",
       "      <th>geom_mean_of_odds</th>\n",
       "      <th>discover answer id</th>\n",
       "      <th>answer name</th>\n",
       "      <th>answer resolved probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>177</td>\n",
       "      <td>2466</td>\n",
       "      <td>2018-03-08</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.223885</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.416046</td>\n",
       "      <td>561</td>\n",
       "      <td>Less than 2,000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>177</td>\n",
       "      <td>2466</td>\n",
       "      <td>2018-03-09</td>\n",
       "      <td>0.221667</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.157849</td>\n",
       "      <td>0.221667</td>\n",
       "      <td>0.207689</td>\n",
       "      <td>561</td>\n",
       "      <td>Less than 2,000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>177</td>\n",
       "      <td>2466</td>\n",
       "      <td>2018-03-10</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>561</td>\n",
       "      <td>Less than 2,000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>177</td>\n",
       "      <td>2466</td>\n",
       "      <td>2018-03-11</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>561</td>\n",
       "      <td>Less than 2,000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>177</td>\n",
       "      <td>2466</td>\n",
       "      <td>2018-03-12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>561</td>\n",
       "      <td>Less than 2,000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   discover question id answer id        date  raw_mean  median  \\\n",
       "0                   177      2466  2018-03-08  0.390000    0.50   \n",
       "1                   177      2466  2018-03-09  0.221667    0.20   \n",
       "2                   177      2466  2018-03-10  0.033333    0.05   \n",
       "3                   177      2466  2018-03-11  0.100000    0.10   \n",
       "4                   177      2466  2018-03-12  0.000000    0.00   \n",
       "\n",
       "   geometric_mean  trimmed_mean  geom_mean_of_odds  discover answer id  \\\n",
       "0        0.223885      0.390000           0.416046                 561   \n",
       "1        0.157849      0.221667           0.207689                 561   \n",
       "2        0.000000      0.033333           0.000000                 561   \n",
       "3        0.000000      0.100000           0.000000                 561   \n",
       "4        0.000000      0.000000           0.000000                 561   \n",
       "\n",
       "       answer name  answer resolved probability  \n",
       "0  Less than 2,000                          1.0  \n",
       "1  Less than 2,000                          1.0  \n",
       "2  Less than 2,000                          1.0  \n",
       "3  Less than 2,000                          1.0  \n",
       "4  Less than 2,000                          1.0  "
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df = id_aggregated_df.merge(\n",
    "    resolved_probabilities_df,\n",
    "    on=['discover question id', 'discover answer id'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "comparison_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I calculate the Brier score for each aggregation method.\n",
    "Since Brier score requires the probabilities for calculation, I convert the Geometric Mean of Odds back to probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df['geom_mean_of_odds_prob'] = comparison_df['geom_mean_of_odds'] / (1 + comparison_df['geom_mean_of_odds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brier Score for raw_mean: 0.1286\n",
      "Brier Score for median: 0.1296\n",
      "Brier Score for geometric_mean: 0.1344\n",
      "Brier Score for trimmed_mean: 0.1285\n",
      "Brier Score for geom_mean_of_odds_prob: 0.1341\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "brier_scores = {}\n",
    "\n",
    "aggregation_methods = ['raw_mean', 'median', 'geometric_mean', 'trimmed_mean', 'geom_mean_of_odds_prob']\n",
    "\n",
    "for method in aggregation_methods:\n",
    "    score = brier_score_loss(comparison_df['answer resolved probability'], comparison_df[method])\n",
    "    brier_scores[method] = score\n",
    "\n",
    "for method, score in brier_scores.items():\n",
    "    print(f\"Brier Score for {method}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the calculated Brier scores, the aggregation methods with highest level of performance on this dataset are the *trimmed mean* and the *raw mean*. Both methods aggregate forecasts by taking averages across all question-answer-day combinations, with the key difference being that the trimmed mean excludes the top and bottom 10% of extreme probability values. This exclusion helps mitigate the impact of predictions that might be less reliable or overly optimistic/pessimistic, leading to forecasts that better reflect the central tendency of the data.\n",
    "\n",
    "The *median* performed slighly less accurately than the raw mean and the trimmed mean, though the difference in the Brier score is very little. The median’s performance is close to the raw mean and trimmed mean but slightly less accurate, likely because it does not consider the full distribution of predictions.\n",
    "\n",
    "The *geometric mean* and the *geometric mean of odds* exhibited the worst performance compared to the other methods. The geometric mean may perform poorly on this dataset due to a significant number of probabilities being close to zero. Since the geometric mean involves multiplying all values together and then taking the root, a large number of small values (or zeros) can lead to an aggregation that is heavily skewed towards lower values, resulting in more moderate aggregated probabilities compared to methods like the mean and median.\n",
    "\n",
    "Also, with geometric mean and the geometric mean of odds if any probability within a set for aggregation is zero, then the aggregation will be 0 as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_daily_forecasts_df.head()\n",
    "\n",
    "idf_df = individual_daily_forecasts_df\n",
    "\n",
    "## calculate the variance of the forecasted probabilities across days for each question-answer pair\n",
    "grouped_idf_df = idf_df.groupby(['discover question id', 'answer id'])\n",
    "\n",
    "variance_df = grouped_idf_df['forecasted probability'].var().reset_index(name='variance')\n",
    "\n",
    "## since the variance of groups with 1 observation is automatically filled as NA, I fill the NA values with 0\n",
    "variance_df['variance'] = variance_df['variance'].fillna(0)\n",
    "\n",
    "idf_df = idf_df.merge(variance_df, on=['discover question id', 'answer id'])\n",
    "\n",
    "## calculate the weights of the foresasts based on the variance\n",
    "idf_df['weights'] = (1 - idf_df['variance']).clip(lower=0)\n",
    "\n",
    "## weight is assigned as 1 - variance * probability\n",
    "idf_df['weighted probability'] = idf_df['weights'] * idf_df['forecasted probability']\n",
    "\n",
    "## calculate the weighted mean of the forecasted probabilities for each question-answer pair\n",
    "weighted_idfs = idf_df.groupby(['discover question id', 'answer id', 'date'])['weighted probability'].mean().reset_index(name='weighted_forecast')\n",
    "\n",
    "weighted_comparison = weighted_idfs.merge(answer_id_df, on=['discover question id', 'answer id'])\n",
    "\n",
    "weighted_comparison = weighted_comparison.merge(qa_df[['discover question id', 'discover answer id', 'answer resolved probability']],\n",
    "                                    on=['discover question id', 'discover answer id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brier Score for weighted forecast: 0.1267\n"
     ]
    }
   ],
   "source": [
    "brier_score = brier_score_loss(\n",
    "    weighted_comparison['answer resolved probability'], \n",
    "    weighted_comparison['weighted_forecast']\n",
    ")\n",
    "\n",
    "print(f\"Brier Score for Weighted Forecast probabilities: {brier_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I implemented the forecast aggregation based on the *mean of weighted probabilities*. The weights are derived from the variance of forecast probabilities across days, so this method leverages variance as a proxy for the certainty of forecasts.\n",
    "In this case the assigned weights were calculated as:\n",
    "\n",
    "1 - Forecast probability variance across days\n",
    "\n",
    "The assumption of this method is that forecast probabilities with higher variance over time indicate greater uncertainty. Higher variance implies that the forecasters are less confident in their predictions, so these forecasts should contribute less to the aggregated forecast. Hence, they are also assigned lower weights compared to the foreasts with lower variance across days.\n",
    "\n",
    "This method also received the lowest Brier score, compared to other methods including those that performed the best on this dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
